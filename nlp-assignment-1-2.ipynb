{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-16T12:55:49.617766Z","iopub.execute_input":"2025-02-16T12:55:49.618172Z","iopub.status.idle":"2025-02-16T12:55:49.970997Z","shell.execute_reply.started":"2025-02-16T12:55:49.618142Z","shell.execute_reply":"2025-02-16T12:55:49.970209Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Practice Exercises","metadata":{}},{"cell_type":"markdown","source":"## Text Preprocessing with NLTK and spaCy","metadata":{}},{"cell_type":"code","source":"from string import punctuation\n\nsample_paragraph = '''\nNatural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. Challenges in natural language processing frequently involve natural language understanding, natural language generation (frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof.\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T12:55:50.273206Z","iopub.execute_input":"2025-02-16T12:55:50.273658Z","iopub.status.idle":"2025-02-16T12:55:50.278019Z","shell.execute_reply.started":"2025-02-16T12:55:50.273630Z","shell.execute_reply":"2025-02-16T12:55:50.277004Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# NLTK\nimport nltk\nimport subprocess\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nnltk.download(\"wordnet\", download_dir='/kaggle/working/')\ncommand = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\nsubprocess.run(command.split())\nnltk.data.path.append('/kaggle/working/')\n\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\nnltk_tokenized = word_tokenize(sample_paragraph)\nnltk_output = [lemmatizer.lemmatize(token.lower().strip()) for token in nltk_tokenized] \nnltk_output = [word for word in nltk_output if word not in stop_words and word not in punctuation] \nprint(nltk_output)\nprint(len(nltk_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T12:55:52.386958Z","iopub.execute_input":"2025-02-16T12:55:52.387286Z","iopub.status.idle":"2025-02-16T12:55:55.525666Z","shell.execute_reply.started":"2025-02-16T12:55:52.387259Z","shell.execute_reply":"2025-02-16T12:55:55.524871Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\n['natural', 'language', 'processing', 'nlp', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistics', 'concerned', 'interaction', 'computer', 'human', 'natural', 'language', 'particular', 'concerned', 'programming', 'computer', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpus', 'challenge', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'language', 'generation', 'frequently', 'formal', 'machine-readable', 'logical', 'form', 'connecting', 'language', 'machine', 'perception', 'managing', 'human-computer', 'dialog', 'system', 'combination', 'thereof']\n54\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# spacy\n\nimport spacy\nfrom spacy.lang.en import stop_words\n  \nnlp = spacy.load(\"en_core_web_sm\")\nstop_words = stop_words.STOP_WORDS\n  \nspacy_res = nlp(sample_paragraph)\nspacy_output = [token.lemma_.lower().strip() for token in spacy_res]\nspacy_output = [word for word in spacy_output if word not in stop_words and word not in punctuation]\nprint(spacy_output)\nprint(len(spacy_output))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T12:55:55.526963Z","iopub.execute_input":"2025-02-16T12:55:55.527513Z","iopub.status.idle":"2025-02-16T12:56:03.503556Z","shell.execute_reply.started":"2025-02-16T12:55:55.527485Z","shell.execute_reply":"2025-02-16T12:56:03.502459Z"}},"outputs":[{"name":"stdout","text":"['natural', 'language', 'processing', 'nlp', 'field', 'computer', 'science', 'artificial', 'intelligence', 'computational', 'linguistic', 'concern', 'interaction', 'computer', 'human', 'natural', 'language', 'particular', 'concern', 'programming', 'computer', 'fruitfully', 'process', 'large', 'natural', 'language', 'corpora', 'challenge', 'natural', 'language', 'processing', 'frequently', 'involve', 'natural', 'language', 'understanding', 'natural', 'language', 'generation', 'frequently', 'formal', 'machine', 'readable', 'logical', 'form', 'connect', 'language', 'machine', 'perception', 'manage', 'human', 'computer', 'dialog', 'system', 'combination', 'thereof']\n56\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(len(set(spacy_output)))\nprint(len((set(nltk_output))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:04:01.613230Z","iopub.execute_input":"2025-02-16T13:04:01.613566Z","iopub.status.idle":"2025-02-16T13:04:01.618147Z","shell.execute_reply.started":"2025-02-16T13:04:01.613536Z","shell.execute_reply":"2025-02-16T13:04:01.617045Z"}},"outputs":[{"name":"stdout","text":"37\n38\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# NER","metadata":{}},{"cell_type":"code","source":"import spacy\nfrom spacy import displacy\n\nsample_paragraph = '''\nA call for American independence from Britain,\nthe Virginia Declaration of Rights was drafted\nby George Mason in May 1776\n'''\n\nnlp = spacy.load('en_core_web_sm')\n\ntext = nlp(sample_paragraph)\n\nfor word in text.ents:\n    print(f\"{word.text} --> {word.label_}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:20:56.456732Z","iopub.execute_input":"2025-02-16T13:20:56.457123Z","iopub.status.idle":"2025-02-16T13:20:57.171868Z","shell.execute_reply.started":"2025-02-16T13:20:56.457091Z","shell.execute_reply":"2025-02-16T13:20:57.170876Z"}},"outputs":[{"name":"stdout","text":"American --> NORP\nBritain --> GPE\nthe Virginia Declaration of Rights --> LAW\nGeorge Mason --> PERSON\nMay 1776 --> DATE\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"text.user_data[\"title\"] = \"Visualizing the named entities using displacy\"\ndisplacy.render(text, style=\"ent\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:21:49.439752Z","iopub.execute_input":"2025-02-16T13:21:49.440145Z","iopub.status.idle":"2025-02-16T13:21:49.447629Z","shell.execute_reply.started":"2025-02-16T13:21:49.440111Z","shell.execute_reply":"2025-02-16T13:21:49.446793Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">Visualizing the named entities using displacy</h2>\n\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>A call for \n<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    American\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n</mark>\n independence from \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Britain\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n,<br>\n<mark class=\"entity\" style=\"background: #ff8197; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    the Virginia Declaration of Rights\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LAW</span>\n</mark>\n was drafted<br>by \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    George Mason\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n in \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    May 1776\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n<br></div></span>"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"# Text Vectorization using Transformers","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\n\nmodel = AutoModel.from_pretrained(\"google-bert/bert-base-uncased\")\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:30:12.736606Z","iopub.execute_input":"2025-02-16T13:30:12.737005Z","iopub.status.idle":"2025-02-16T13:30:12.956582Z","shell.execute_reply.started":"2025-02-16T13:30:12.736974Z","shell.execute_reply":"2025-02-16T13:30:12.955541Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"inputs = tokenizer(sample_paragraph, return_tensors=\"pt\")\nwith torch.no_grad():\n    outputs = model(**inputs)\nhidden_states = outputs.last_hidden_state\nword_embeddings = hidden_states.squeeze(0).numpy()\nprint(\"Shape:\", word_embeddings.shape)\nprint(word_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T13:30:25.797857Z","iopub.execute_input":"2025-02-16T13:30:25.798250Z","iopub.status.idle":"2025-02-16T13:30:25.890178Z","shell.execute_reply.started":"2025-02-16T13:30:25.798209Z","shell.execute_reply":"2025-02-16T13:30:25.889310Z"}},"outputs":[{"name":"stdout","text":"Shape: (23, 768)\n[[-0.47192803 -0.08309454 -0.23628114 ... -0.5588365  -0.23242825\n   0.45167467]\n [-0.29248115 -0.21373485 -0.8013402  ... -0.36817613 -0.02976469\n   0.16252461]\n [-0.17263797 -0.48235747  0.04862721 ... -0.7239995  -0.12700519\n  -0.7586211 ]\n ...\n [-0.8432871  -0.6246966  -0.60949767 ... -0.951172   -0.59483546\n  -0.08086661]\n [ 0.3762518  -0.54389703 -0.28336224 ... -0.47434962 -0.44405395\n   0.87907517]\n [ 0.47661605  0.06666544 -0.38012972 ... -0.031454   -0.6429229\n   0.10792677]]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"# Sentiment Analysis with Transformers","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nsentiment_pipeline = pipeline(\"sentiment-analysis\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:43:26.337490Z","iopub.execute_input":"2025-02-16T16:43:26.337929Z","iopub.status.idle":"2025-02-16T16:43:53.243302Z","shell.execute_reply.started":"2025-02-16T16:43:26.337887Z","shell.execute_reply":"2025-02-16T16:43:53.242234Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85f38079ec624d7cb455238321a52ef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1417f4ecfde4fa7b8e79e817ba55056"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27a4a983a58441458bef117e4f521c88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b783f62666504de0b9f8329c4909d804"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"sentences = [\n    \"I love the new phone, it's absolutely amazing!\",\n    \"The weather today is okay, nothing special.\",\n    \"I hate waiting in long lines, it's so frustrating.\",\n    \"nothing bad\"\n]\n\nresults = sentiment_pipeline(sentences)\n\nfor sent, res in zip(sentences, results):\n    print(f\"Sentence: {sent}\\nPrediction: {res['label']}, Confidence: {res['score']:.4f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:48:44.053410Z","iopub.execute_input":"2025-02-16T16:48:44.053729Z","iopub.status.idle":"2025-02-16T16:48:44.080318Z","shell.execute_reply.started":"2025-02-16T16:48:44.053700Z","shell.execute_reply":"2025-02-16T16:48:44.079655Z"}},"outputs":[{"name":"stdout","text":"Sentence: I love the new phone, it's absolutely amazing!\nPrediction: POSITIVE, Confidence: 0.9999\n\nSentence: The weather today is okay, nothing special.\nPrediction: NEGATIVE, Confidence: 0.9952\n\nSentence: I hate waiting in long lines, it's so frustrating.\nPrediction: NEGATIVE, Confidence: 0.9984\n\nSentence: nothing bad\nPrediction: POSITIVE, Confidence: 0.9987\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### Traditional text-processing approaches","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\nnltk.download(\"vader_lexicon\")\n\nsia = SentimentIntensityAnalyzer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:48:46.663972Z","iopub.execute_input":"2025-02-16T16:48:46.664299Z","iopub.status.idle":"2025-02-16T16:48:46.674639Z","shell.execute_reply.started":"2025-02-16T16:48:46.664271Z","shell.execute_reply":"2025-02-16T16:48:46.673823Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Perform sentiment analysis using Vader\nfor sentence in sentences:\n    score = sia.polarity_scores(sentence)\n    sentiment = \"POSITIVE\" if score['compound'] > 0 else \"NEGATIVE\" if score['compound'] < 0 else \"NEUTRAL\"\n    print(f\"Sentence: {sentence}\\nPrediction: {sentiment}, Confidence: {score['compound']}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:48:46.795481Z","iopub.execute_input":"2025-02-16T16:48:46.795742Z","iopub.status.idle":"2025-02-16T16:48:46.801337Z","shell.execute_reply.started":"2025-02-16T16:48:46.795720Z","shell.execute_reply":"2025-02-16T16:48:46.800543Z"}},"outputs":[{"name":"stdout","text":"Sentence: I love the new phone, it's absolutely amazing!\nPrediction: POSITIVE, Confidence: 0.862\n\nSentence: The weather today is okay, nothing special.\nPrediction: NEGATIVE, Confidence: -0.092\n\nSentence: I hate waiting in long lines, it's so frustrating.\nPrediction: NEGATIVE, Confidence: -0.8147\n\nSentence: nothing bad\nPrediction: POSITIVE, Confidence: 0.431\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}